{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-be85b16f-ad34-4cfa-968b-f44f7ea08cca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1622728924694,
    "id": "5ZlacYIWCqWM",
    "source_hash": "2de0bc20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Based on: https://www.tensorflow.org/lite/guide/python\n",
    "# And then https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/python/\n",
    "\n",
    "# If running on colab - you'll need to attach\n",
    "from google.colab import drive\n",
    "drive.mount('/$USER/tensorflow_datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build (if necessary) and then import the british birds dataset...\n",
    "\n",
    "PRO-TIP:\n",
    "Adding to this if you’re worried if the colab could be disconnecting you can run a small following Java script code going to the console by clicking Ctrl+ Shift + i in your browser.\n",
    "\n",
    "    function ClickConnect(){\n",
    "      console.log(\"Working\"); \n",
    "      document.querySelector(\"colab-toolbar-button#connect\").click() \n",
    "    }setInterval(ClickConnect,60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO[build.py]: Loading dataset ../datasets/britishbirds from path: /Users/tim/Code/github/birdsong/datasets/britishbirds/britishbirds.py\n",
      "2022-02-21 21:36:19.681225: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n",
      "INFO[build.py]: download_and_prepare for dataset britishbirds/1.0.0...\n",
      "INFO[dataset_builder.py]: Generating dataset britishbirds (/Users/tim/tensorflow_datasets/britishbirds/1.0.0)\n",
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/tim/tensorflow_datasets/britishbirds/1.0.0...\u001b[0m\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "                                        ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\u001b[AINFO[download_manager.py]: Downloading https://archive.org/compress/xccoverbl_2014 into /Users/tim/tensorflow_datasets/downloads/archive.org_compress_xccoverbl_2014oOEgG5cTsFeBnYLXxzQOuanvK2M5Lqlt0YaoWcKjDj4.tmp.3685e4d8d7e9445dba7f35ed98f2ec0f...\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:01<?, ? url/s]\n",
      "Dl Size...:   0%|                                     | 0/712 [00:01<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:   0%|                             | 1/712 [00:02<35:00,  2.95s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:   0%|                             | 2/712 [00:03<16:38,  1.41s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:   0%|                             | 3/712 [00:03<10:50,  1.09 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▏                            | 4/712 [00:04<08:51,  1.33 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▏                            | 5/712 [00:04<06:23,  1.84 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▏                            | 6/712 [00:04<05:35,  2.10 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▎                            | 7/712 [00:04<04:25,  2.65 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▎                            | 8/712 [00:05<04:46,  2.45 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▎                            | 9/712 [00:05<04:33,  2.57 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:06<?, ? url/s]\u001b[A\n",
      "Dl Size...:   1%|▍                           | 10/712 [00:06<05:25,  2.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:06, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:07<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▍                           | 11/712 [00:07<06:36,  1.77 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:07, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:08<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▍                           | 12/712 [00:08<10:05,  1.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:12<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▌                           | 13/712 [00:12<21:02,  1.81s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:12, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:17<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▌                           | 14/712 [00:17<30:47,  2.65s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:22<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▌                           | 15/712 [00:22<40:19,  3.47s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:28<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▋                           | 16/712 [00:28<49:24,  4.26s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:33<?, ? url/s]\u001b[A\n",
      "Dl Size...:   2%|▋                           | 17/712 [00:33<52:12,  4.51s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:33, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:41<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▋                         | 18/712 [00:41<1:01:58,  5.36s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:48<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▋                         | 19/712 [00:48<1:09:07,  5.99s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:48, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [00:56<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▋                         | 20/712 [00:56<1:16:31,  6.64s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:56, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:02<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▊                         | 21/712 [01:02<1:13:44,  6.40s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:10<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▊                         | 22/712 [01:10<1:19:45,  6.93s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:10, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:16<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▊                         | 23/712 [01:16<1:16:16,  6.64s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:21<?, ? url/s]\u001b[A\n",
      "Dl Size...:   3%|▉                         | 24/712 [01:21<1:09:14,  6.04s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:27<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|▉                         | 25/712 [01:27<1:11:01,  6.20s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:27, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:32<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|▉                         | 26/712 [01:32<1:06:45,  5.84s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:40<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|▉                         | 27/712 [01:40<1:11:30,  6.26s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:40, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:46<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█                         | 28/712 [01:46<1:12:51,  6.39s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:46, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:49<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█                         | 29/712 [01:49<1:01:42,  5.42s/ MiB]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [01:49, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:53<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█▏                          | 30/712 [01:53<54:58,  4.84s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:53, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [01:56<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█▏                          | 31/712 [01:56<49:04,  4.32s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [01:56, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   4%|█▎                          | 32/712 [02:04<59:57,  5.29s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:11<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▏                        | 33/712 [02:11<1:05:26,  5.78s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:15<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▏                        | 34/712 [02:15<1:00:03,  5.32s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:17<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▍                          | 35/712 [02:17<48:13,  4.27s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:19<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▍                          | 36/712 [02:19<42:38,  3.78s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:19, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:22<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▍                          | 37/712 [02:22<37:31,  3.34s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:25<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▍                          | 38/712 [02:25<38:20,  3.41s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:25, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:32<?, ? url/s]\u001b[A\n",
      "Dl Size...:   5%|█▌                          | 39/712 [02:32<51:06,  4.56s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:38<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▌                          | 40/712 [02:38<55:29,  4.95s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:42<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▌                          | 41/712 [02:42<50:41,  4.53s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:42, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:47<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                          | 42/712 [02:47<51:17,  4.59s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:47, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:52<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                          | 43/712 [02:52<55:28,  4.98s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:52, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [02:57<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                          | 44/712 [02:57<55:46,  5.01s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [02:57, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                        | 45/712 [03:05<1:04:03,  5.76s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:11<?, ? url/s]\u001b[A\n",
      "Dl Size...:   6%|█▋                        | 46/712 [03:11<1:06:00,  5.95s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:11, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:16<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▊                          | 47/712 [03:16<59:52,  5.40s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:16, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:21<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▊                        | 48/712 [03:21<1:00:31,  5.47s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:21, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:28<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▊                        | 49/712 [03:28<1:05:18,  5.91s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:28, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:37<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▊                        | 50/712 [03:37<1:13:38,  6.67s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:37, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:49<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▊                        | 51/712 [03:49<1:32:53,  8.43s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:49, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [03:57<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▉                        | 52/712 [03:57<1:30:15,  8.21s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [03:57, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:04<?, ? url/s]\u001b[A\n",
      "Dl Size...:   7%|█▉                        | 53/712 [04:04<1:26:45,  7.90s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:04, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:17<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|█▉                        | 54/712 [04:17<1:43:45,  9.46s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:17, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:26<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██                        | 55/712 [04:26<1:40:39,  9.19s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:26, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:32<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██                        | 56/712 [04:32<1:32:42,  8.48s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:32, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:38<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██                        | 57/712 [04:38<1:23:19,  7.63s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:38, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:43<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██                        | 58/712 [04:43<1:15:16,  6.91s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:43, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:50<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██▏                       | 59/712 [04:50<1:15:01,  6.89s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:50, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [04:58<?, ? url/s]\u001b[A\n",
      "Dl Size...:   8%|██▏                       | 60/712 [04:58<1:17:01,  7.09s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [04:58, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▏                       | 61/712 [05:03<1:11:48,  6.62s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:03, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:08<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▎                       | 62/712 [05:08<1:06:21,  6.13s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:08, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:15<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▎                       | 63/712 [05:15<1:10:01,  6.47s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:22<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▎                       | 64/712 [05:22<1:10:40,  6.54s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:29<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▎                       | 65/712 [05:29<1:11:43,  6.65s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:29, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:36<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▍                       | 66/712 [05:36<1:12:30,  6.73s/ MiB]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed...: 0 file [05:36, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:41<?, ? url/s]\u001b[A\n",
      "Dl Size...:   9%|██▍                       | 67/712 [05:41<1:07:33,  6.28s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:49<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▍                       | 68/712 [05:49<1:12:32,  6.76s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:49, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [05:56<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▌                       | 69/712 [05:56<1:13:56,  6.90s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [05:56, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:05<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▌                       | 70/712 [06:05<1:18:52,  7.37s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:05, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:15<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▌                       | 71/712 [06:15<1:27:44,  8.21s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:15, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:22<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▋                       | 72/712 [06:22<1:23:53,  7.87s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:22, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:31<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▋                       | 73/712 [06:31<1:27:57,  8.26s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:31, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:35<?, ? url/s]\u001b[A\n",
      "Dl Size...:  10%|██▋                       | 74/712 [06:35<1:14:02,  6.96s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:35, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:41<?, ? url/s]\u001b[A\n",
      "Dl Size...:  11%|██▋                       | 75/712 [06:41<1:10:10,  6.61s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:41, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:48<?, ? url/s]\u001b[A\n",
      "Dl Size...:  11%|██▊                       | 76/712 [06:48<1:09:59,  6.60s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:48, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [06:56<?, ? url/s]\u001b[A\n",
      "Dl Size...:  11%|██▊                       | 77/712 [06:56<1:16:00,  7.18s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [06:56, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [07:00<?, ? url/s]\u001b[A\n",
      "Dl Size...:  11%|██▊                       | 78/712 [07:00<1:05:09,  6.17s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [07:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|                                  | 0/1 [07:03<?, ? url/s]\u001b[A\n",
      "Dl Size...:  11%|███                         | 79/712 [07:03<54:50,  5.20s/ MiB]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [07:03, ? file/s]\u001b[A\u001b[A^C\n",
      "Extraction completed...: 0 file [07:06, ? file/s]\n",
      "Dl Size...:  11%|███                         | 79/712 [07:06<56:59,  5.40s/ MiB]\n",
      "Dl Completed...:   0%|                                  | 0/1 [07:06<?, ? url/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/bin/tfds\", line 8, in <module>\n",
      "    sys.exit(launch_cli())\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/scripts/cli/main.py\", line 102, in launch_cli\n",
      "    app.run(main, flags_parser=_parse_flags)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/scripts/cli/main.py\", line 97, in main\n",
      "    args.subparser_fn(args)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/scripts/cli/build.py\", line 192, in _build_datasets\n",
      "    _download_and_prepare(args, builder)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/scripts/cli/build.py\", line 343, in _download_and_prepare\n",
      "    builder.download_and_prepare(\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 460, in download_and_prepare\n",
      "    self._download_and_prepare(\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 1157, in _download_and_prepare\n",
      "    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n",
      "  File \"/Users/tim/Code/github/birdsong/datasets/britishbirds/britishbirds.py\", line 86, in _split_generators\n",
      "    dl_path = dl_manager.download_and_extract(\"britishbirds\",_DOWNLOAD_URL)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 634, in download_and_extract\n",
      "    return _map_promise(self._download_extract, url_or_urls)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 767, in _map_promise\n",
      "    res = tf.nest.map_structure(lambda p: p.get(), all_promises)  # Wait promises\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow/python/util/nest.py\", line 869, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow/python/util/nest.py\", line 869, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 767, in <lambda>\n",
      "    res = tf.nest.map_structure(lambda p: p.get(), all_promises)  # Wait promises\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/promise/promise.py\", line 511, in get\n",
      "    self._wait(timeout or DEFAULT_TIMEOUT)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/promise/promise.py\", line 506, in _wait\n",
      "    self.wait(self, timeout)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/promise/promise.py\", line 502, in wait\n",
      "    async_instance.wait(promise, timeout)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/promise/async_.py\", line 117, in wait\n",
      "    target.scheduler.wait(target, timeout)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/site-packages/promise/schedulers/immediate.py\", line 25, in wait\n",
      "    waited = e.wait(timeout)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/local/anaconda3/envs/birdsong/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# If you haven't build the dataset, you need to go there and do that first...\n",
    "#########################\n",
    "# THIS WILL DOWNLOAD ALL THE DATA - YOU ONLY NEED TO RUN THIS ONCE\n",
    "# If you do this in Colab - make sure you have the space by mounting drive!\n",
    "#########################\n",
    "!tfds build ../datasets/britishbirds\n",
    "\n",
    "# You can then...\n",
    "#import sys\n",
    "#sys.path.append(\"../\")\n",
    "#import datasets.britishbirds\n",
    "#\n",
    "#ds = tfds.load('britishbirds')  # `my_dataset` registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00001-fcc3299e-01a3-429d-bbcc-3e6d18354763",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3943,
    "execution_start": 1622728928228,
    "id": "ZyUPqzP1CqWP",
    "outputId": "7148e0cf-1868-43c5-f081-b30837291d64",
    "source_hash": "b1d59faa",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'carbontracker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcarbontracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CarbonTracker\n\u001b[1;32m      3\u001b[0m tracker \u001b[38;5;241m=\u001b[39m CarbonTracker(epochs\u001b[38;5;241m=\u001b[39mmax_epochs)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'carbontracker'"
     ]
    }
   ],
   "source": [
    "from carbontracker.tracker import CarbonTracker\n",
    "\n",
    "tracker = CarbonTracker(epochs=max_epochs)\n",
    "\n",
    "#!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00004-8ad926e8-17df-4a08-a6fc-66e45933154c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5413,
    "execution_start": 1622729958534,
    "id": "7entper4CqWQ",
    "outputId": "56fcbeeb-735d-4052-acde-5437c4c74e6c",
    "source_hash": "d03b25e0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  918k  100  918k    0     0  3506k      0 --:--:-- --:--:-- --:--:-- 3506k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0./\n",
      "./mobilenet_v1_1.0_224.tflite\n",
      "  5 89.9M    5 4904k    0     0  6582k      0  0:00:13 --:--:--  0:00:13 6573k./mobilenet_v1_1.0_224.ckpt.meta\n",
      "./mobilenet_v1_1.0_224.ckpt.index\n",
      "./mobilenet_v1_1.0_224.ckpt.data-00000-of-00001\n",
      " 26 89.9M   26 24.0M    0     0  13.8M      0  0:00:06  0:00:01  0:00:05 13.8M./mobilenet_v1_1.0_224_info.txt\n",
      "./mobilenet_v1_1.0_224_frozen.pb\n",
      "100 89.9M  100 89.9M    0     0  31.5M      0  0:00:02  0:00:02 --:--:-- 31.4M\n",
      "./mobilenet_v1_1.0_224_eval.pbtxt\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0 18.2M    0  132k    0     0   158k      0  0:01:58 --:--:--  0:01:58  158kmobilenet_v1_1.0_224/labels.txt\n",
      "100 18.2M  100 18.2M    0     0  11.6M      0  0:00:01  0:00:01 --:--:-- 11.6M\n"
     ]
    }
   ],
   "source": [
    "# Get photo\n",
    "!curl https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/examples/label_image/testdata/grace_hopper.bmp > /tmp/grace_hopper.bmp\n",
    "# Get model\n",
    "!curl https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz | tar xzv -C /tmp\n",
    "# Get labels\n",
    "!curl https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz  | tar xzv -C /tmp  mobilenet_v1_1.0_224/labels.txt\n",
    "\n",
    "!mv /tmp/mobilenet_v1_1.0_224/labels.txt /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-3427b6a1-9915-4bf2-8e6b-1b5f548794fd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1622729972044,
    "id": "rCldNMx9CqWR",
    "source_hash": "ce46591c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_file = \"/tmp/mobilenet_v1_1.0_224.tflite\"\n",
    "label_file = \"/tmp/labels.txt\"\n",
    "image_file = \"/tmp/grace_hopper.bmp\"\n",
    "input_mean = 127.5\n",
    "input_std = 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00003-75eede2b-34a7-4907-b699-1d1b3619e64b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1622730084385,
    "id": "zUJAgy8uCqWR",
    "outputId": "657e251f-4c70-4bc4-cd19-6baaac9a1419",
    "source_hash": "7055f8e3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919721: 653:military uniform\n",
      "0.017762: 907:Windsor tie\n",
      "0.007507: 668:mortarboard\n",
      "0.005419: 466:bulletproof vest\n",
      "0.003828: 458:bow tie, bow-tie, bowtie\n",
      "time: 113.866ms\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "def load_labels(filename):\n",
    "  with open(filename, 'r') as f:\n",
    "    return [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "interpreter = tflite.Interpreter(model_path=model_file)\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check the type of the input tensor\n",
    "floating_model = input_details[0]['dtype'] == np.float32\n",
    "\n",
    "# NxHxWxC, H:1, W:2\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "img = Image.open(image_file).resize((width, height))\n",
    "\n",
    "# add N dim\n",
    "input_data = np.expand_dims(img, axis=0)\n",
    "\n",
    "if floating_model:\n",
    "  input_data = (np.float32(input_data) - input_mean) / input_std\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "start_time = time.time()\n",
    "interpreter.invoke()\n",
    "stop_time = time.time()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "results = np.squeeze(output_data)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "labels = load_labels(label_file)\n",
    "for i in top_k:\n",
    "  if floating_model:\n",
    "    print('{:08.6f}: {}'.format(float(results[i]), labels[i]))\n",
    "  else:\n",
    "    print('{:08.6f}: {}'.format(float(results[i] / 255.0), labels[i]))\n",
    "\n",
    "print('time: {:.3f}ms'.format((stop_time - start_time) * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "ytJF7D7REAVr",
    "outputId": "fdce3085-4f6e-4bcd-c23f-c0a7f79be8eb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8cf71051c5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert the model to the TensorFlow Lite format without quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"sine_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
    "# Indicate that we want to perform the default optimizations,\n",
    "# which include quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Define a generator function that provides our test data's x values\n",
    "# as a representative dataset, and tell the converter to use it\n",
    "def representative_dataset_generator():\n",
    "  for value in x_test:\n",
    "    # Each scalar value must be inside of a 2D array that is wrapped in a list\n",
    "    yield [np.array(value, dtype=np.float32, ndmin=2)]\n",
    "converter.representative_dataset = representative_dataset_generator\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"sine_model_quantized.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "birdsong.ipynb",
   "provenance": []
  },
  "deepnote": {
   "is_reactive": false
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
